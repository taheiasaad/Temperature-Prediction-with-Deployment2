{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6oOFVSrTgoXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model_before_Pettit=pd.read_csv(\"df_model_before_Pettit.csv\")\n",
        "df_model_after_Pettit=pd.read_csv(\"df_model_after_Pettit.csv\")"
      ],
      "metadata": {
        "id": "t2kh82Nvgnp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model_after_Pettit.drop([\"Day_Night\",\"Wind_Direction\"],axis=1,inplace=True)\n"
      ],
      "metadata": {
        "id": "GZ06b-Ju8FQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_after = df_model_after_Pettit.drop('Temp - °C', axis=1)\n",
        "y_after = df_model_after_Pettit['Temp - °C']\n",
        "\n",
        "split = int(len(X_after) * 0.8)\n",
        "X_train_after, X_test_after = X_after[:split], X_after[split:]\n",
        "y_train_after, y_test_after = y_after[:split], y_after[split:]"
      ],
      "metadata": {
        "id": "enLscZs5gqeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLxLS6Xrfnmu"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# --- Scale Features and Target ---\n",
        "scaler_X = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y = MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "X_train_after_scaled = scaler_X.fit_transform(X_train_after)\n",
        "X_test_after_scaled  = scaler_X.transform(X_test_after)\n",
        "y_train_after_scaled = scaler_y.fit_transform(y_train_after.values.reshape(-1,1))\n",
        "y_test_after_scaled  = scaler_y.transform(y_test_after.values.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(X, y, time_steps=60):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])  # Fixed indexing\n",
        "        ys.append(y[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "\n",
        "# --- After Pettit ---\n",
        "X_train_seq_after, y_train_seq_after   = create_sequences(X_train_after_scaled, y_train_after_scaled,time_steps=60)\n",
        "X_test_seq_after, y_test_seq_after     = create_sequences(X_test_after_scaled, y_test_after_scaled, time_steps=60)\n",
        "\n",
        "print(\"After Pettit train:\", X_train_seq_after.shape, y_train_seq_after.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUv2Y2k7ftm_",
        "outputId": "dce4b41e-eb44-41a3-fa32-18725ae5fdfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Pettit train: (26532, 60, 8) (26532, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(64, activation='tanh', return_sequences=True, input_shape=(X_train_seq_after.shape[1], X_train_seq_after.shape[2])))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(32))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "  return model\n",
        "\n",
        "model_after  = build_lstm((X_train_seq_after.shape[1], X_train_seq_after.shape[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvRi0cZ-ee2U",
        "outputId": "175612f0-9e5c-4afb-d75b-d65c70019b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import callbacks\n",
        "\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6\n",
        ")"
      ],
      "metadata": {
        "id": "Elckk0dxf6yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- After Pettit ---\n",
        "history_after = model_after.fit(\n",
        "    X_train_seq_after, y_train_seq_after,\n",
        "    epochs=50, batch_size=32,\n",
        "    validation_data=(X_test_seq_after, y_test_seq_after),\n",
        "    callbacks=[reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "22v9tLPSf7W_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c56c2d7-c3a9-49bd-f30f-f310a5dcc500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 33ms/step - loss: 0.0270 - val_loss: 0.0073 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - loss: 0.0070 - val_loss: 0.0044 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - loss: 0.0048 - val_loss: 0.0043 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0042 - val_loss: 0.0037 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - loss: 0.0036 - val_loss: 0.0034 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0034 - val_loss: 0.0034 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0033 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - loss: 0.0031 - val_loss: 0.0035 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 31ms/step - loss: 0.0031 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - loss: 0.0028 - val_loss: 0.0033 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0028 - val_loss: 0.0026 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - loss: 0.0028 - val_loss: 0.0027 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - loss: 0.0028 - val_loss: 0.0026 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 32ms/step - loss: 0.0027 - val_loss: 0.0029 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0028 - val_loss: 0.0026 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 32ms/step - loss: 0.0026 - val_loss: 0.0025 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 31ms/step - loss: 0.0025 - val_loss: 0.0024 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - loss: 0.0024 - val_loss: 0.0024 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0025 - val_loss: 0.0024 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - loss: 0.0024 - val_loss: 0.0026 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - loss: 0.0024 - val_loss: 0.0026 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - loss: 0.0024 - val_loss: 0.0026 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - loss: 0.0024 - val_loss: 0.0024 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0023 - val_loss: 0.0024 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 31ms/step - loss: 0.0022 - val_loss: 0.0025 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0023 - val_loss: 0.0024 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 31ms/step - loss: 0.0024 - val_loss: 0.0024 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 31ms/step - loss: 0.0023 - val_loss: 0.0024 - learning_rate: 1.2500e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 31ms/step - loss: 0.0023 - val_loss: 0.0024 - learning_rate: 1.2500e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 32ms/step - loss: 0.0022 - val_loss: 0.0024 - learning_rate: 1.2500e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 1.2500e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 32ms/step - loss: 0.0024 - val_loss: 0.0024 - learning_rate: 1.2500e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0023 - val_loss: 0.0024 - learning_rate: 6.2500e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 6.2500e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0022 - val_loss: 0.0024 - learning_rate: 6.2500e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - loss: 0.0022 - val_loss: 0.0024 - learning_rate: 6.2500e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 33ms/step - loss: 0.0022 - val_loss: 0.0024 - learning_rate: 6.2500e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 32ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 3.1250e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 3.1250e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 3.1250e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 32ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 3.1250e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - loss: 0.0022 - val_loss: 0.0024 - learning_rate: 3.1250e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 32ms/step - loss: 0.0022 - val_loss: 0.0024 - learning_rate: 1.5625e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 1.5625e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - loss: 0.0022 - val_loss: 0.0024 - learning_rate: 1.5625e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 31ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 1.5625e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 1.5625e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 32ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 7.8125e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 32ms/step - loss: 0.0021 - val_loss: 0.0024 - learning_rate: 7.8125e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 33ms/step - loss: 0.0022 - val_loss: 0.0024 - learning_rate: 7.8125e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_after = model_after.predict(X_test_seq_after)\n",
        "y_pred_after_actual = scaler_y.inverse_transform(y_pred_after)\n",
        "y_test_after_actual  = scaler_y.inverse_transform(y_test_seq_after)"
      ],
      "metadata": {
        "id": "Hxs7kiOegAxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7193197d-2c48-4318-ad57-2f94f87d5de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "mae_after = mean_absolute_error(y_test_after_actual, y_pred_after_actual)\n",
        "mse_after = mean_squared_error(y_test_after_actual, y_pred_after_actual)\n",
        "rmse_after = np.sqrt(mse_after)\n",
        "r2_after = r2_score(y_test_after_actual, y_pred_after_actual)\n",
        "\n",
        "print(\"=== After Pettitt ===\")\n",
        "print(f\"MAE  : {mae_after:.4f}\")\n",
        "print(f\"MSE  : {mse_after:.4f}\")\n",
        "print(f\"RMSE : {rmse_after:.4f}\")\n",
        "print(f\"R²   : {r2_after:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF-EhorJAaIo",
        "outputId": "9255a240-ba04-49b5-a897-71a47392d678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== After Pettitt ===\n",
            "MAE  : 0.4163\n",
            "MSE  : 0.3591\n",
            "RMSE : 0.5992\n",
            "R²   : 0.9688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    actual = y_test_after_actual[i][0]  # Extract scalar\n",
        "    pred = y_pred_after_actual[i][0]    # Extract scalar\n",
        "    print(f\"Actual: {actual:.2f}, Predicted: {pred:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st1IJROOdbjg",
        "outputId": "bd5a9568-5258-44c7-a35d-ec00bd3a995b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: 25.30, Predicted: 26.50\n",
            "Actual: 19.90, Predicted: 26.51\n",
            "Actual: 25.60, Predicted: 26.52\n",
            "Actual: 25.40, Predicted: 26.52\n",
            "Actual: 24.00, Predicted: 26.52\n",
            "Actual: 22.80, Predicted: 26.52\n",
            "Actual: 32.10, Predicted: 26.51\n",
            "Actual: 35.50, Predicted: 26.51\n",
            "Actual: 25.10, Predicted: 26.51\n",
            "Actual: 28.90, Predicted: 26.51\n"
          ]
        }
      ]
    }
  ]
}